{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model Validation - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll be able to validate your Ames Housing data model using a train-test split.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Perform a train-test split\n",
    "* Prepare training and testing data for modeling\n",
    "* Compare training and testing errors to determine if model is over or underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Use Our Ames Housing Data Again!\n",
    "\n",
    "We included the code to load the data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "Id                                                                      \n",
       "1             60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "2             20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "3             60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "4             70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "5             60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...          ...      ...          ...      ...    ...   ...      ...   \n",
       "1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... PoolArea PoolQC  Fence MiscFeature  \\\n",
       "Id                                    ...                                      \n",
       "1            Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "2            Lvl    AllPub       FR2  ...        0    NaN    NaN         NaN   \n",
       "3            Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "4            Lvl    AllPub    Corner  ...        0    NaN    NaN         NaN   \n",
       "5            Lvl    AllPub       FR2  ...        0    NaN    NaN         NaN   \n",
       "...          ...       ...       ...  ...      ...    ...    ...         ...   \n",
       "1456         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "1457         Lvl    AllPub    Inside  ...        0    NaN  MnPrv         NaN   \n",
       "1458         Lvl    AllPub    Inside  ...        0    NaN  GdPrv        Shed   \n",
       "1459         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "1460         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "\n",
       "     MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "Id                                                               \n",
       "1          0      2    2008        WD         Normal     208500  \n",
       "2          0      5    2007        WD         Normal     181500  \n",
       "3          0      9    2008        WD         Normal     223500  \n",
       "4          0      2    2006        WD        Abnorml     140000  \n",
       "5          0     12    2008        WD         Normal     250000  \n",
       "...      ...    ...     ...       ...            ...        ...  \n",
       "1456       0      8    2007        WD         Normal     175000  \n",
       "1457       0      2    2010        WD         Normal     210000  \n",
       "1458    2500      5    2010        WD         Normal     266500  \n",
       "1459       0      4    2010        WD         Normal     142125  \n",
       "1460       0      6    2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 80 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "ames = pd.read_csv('ames.csv', index_col=0)\n",
    "ames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Train-Test Split\n",
    "\n",
    "Use `train_test_split` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)) with the default split size. At the end you should have `X_train`, `X_test`, `y_train`, and `y_test` variables, where `y` represents `SalePrice` and `X` represents all other columns. It is also important to set a random state so that your results will be repeatable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(ames, random_state=5)\n",
    "\n",
    "X_train = train.drop(['SalePrice'], axis=1)\n",
    "y_train = train['SalePrice']\n",
    "\n",
    "X_test = test.drop(['SalePrice'], axis=1)\n",
    "y_test = test['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Both Sets for Modeling\n",
    "\n",
    "This code is completed for you and should work as long as the correct variables were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "\n",
    "continuous = ['LotArea', '1stFlrSF', 'GrLivArea']\n",
    "categoricals = ['BldgType', 'KitchenQual', 'Street']\n",
    "\n",
    "# Instantiate transformers\n",
    "log_transformer = FunctionTransformer(np.log, validate=True)\n",
    "ohe = OneHotEncoder(drop='first', sparse=False)\n",
    "\n",
    "# Fit transformers\n",
    "log_transformer.fit(X_train[continuous])\n",
    "ohe.fit(X_train[categoricals])\n",
    "\n",
    "# Transform training data\n",
    "X_train = pd.concat([\n",
    "    pd.DataFrame(log_transformer.transform(X_train[continuous]), index=X_train.index),\n",
    "    pd.DataFrame(ohe.transform(X_train[categoricals]), index=X_train.index)\n",
    "], axis=1)\n",
    "\n",
    "# Transform test data\n",
    "X_test = pd.concat([\n",
    "    pd.DataFrame(log_transformer.transform(X_test[continuous]), index=X_test.index),\n",
    "    pd.DataFrame(ohe.transform(X_test[categoricals]), index=X_test.index)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Linear Regression on the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: import the linear regression model class, initialize a model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here: fit the model to train data\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and Validate Model\n",
    "\n",
    "### Generate Predictions on Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: generate predictions for both sets\n",
    "y_hat_train = linreg.predict(X_train)\n",
    "y_hat_test = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Mean Squared Error (MSE)\n",
    "\n",
    "You can use `mean_squared_error` from scikit-learn ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Squared Error: 1879192792.763197\n",
      "Test Mean Squared Error: 1656252529.9133325\n"
     ]
    }
   ],
   "source": [
    "# Your code here: calculate training and test MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_hat_train)\n",
    "test_mse = mean_squared_error(y_test, y_hat_test)\n",
    "print('Train Mean Squared Error:', train_mse)\n",
    "print('Test Mean Squared Error:', test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your test error is substantially worse than the train error, this is a sign that the model doesn't generalize well to future cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One simple way to demonstrate overfitting and underfitting is to alter the size of our train-test split. By default, scikit-learn allocates 25% of the data to the test set and 75% to the training set. Fitting a model on only 10% of the data is apt to lead to underfitting, while training a model on 99% of the data is apt to lead to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up: Evaluate the Effect of Train-Test Split Size\n",
    "\n",
    "Iterate over a range of train-test split sizes from .5 to .9. For each of these, generate a new train/test split sample. Preprocess both sets of data. Fit a model to the training sample and calculate both the training error and the test error (MSE) for each of these splits. Plot these two curves (train error vs. training size and test error vs. training size) on a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_mses = []\n",
    "test_mses = []\n",
    "\n",
    "X = ames.drop(\"SalePrice\", axis=1)\n",
    "y = ames[\"SalePrice\"]\n",
    "t_sizes = np.linspace(0.5, 0.9, 10)\n",
    "for t_size in t_sizes:\n",
    "    \n",
    "    # Create new split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=t_size, random_state=42)\n",
    "\n",
    "    # Fit transformers on new train and test\n",
    "    log_transformer.fit(X_train[continuous])\n",
    "    ohe.fit(X_train[categoricals])\n",
    "\n",
    "    # Transform training data\n",
    "    X_train = pd.concat([\n",
    "        pd.DataFrame(log_transformer.transform(X_train[continuous]), index=X_train.index),\n",
    "        pd.DataFrame(ohe.transform(X_train[categoricals]), index=X_train.index)\n",
    "    ], axis=1)\n",
    "\n",
    "    # Transform test data\n",
    "    X_test = pd.concat([\n",
    "        pd.DataFrame(log_transformer.transform(X_test[continuous]), index=X_test.index),\n",
    "        pd.DataFrame(ohe.transform(X_test[categoricals]), index=X_test.index)\n",
    "    ], axis=1)\n",
    "\n",
    "    # Fit model\n",
    "    linreg.fit(X_train, y_train)\n",
    "\n",
    "    # Append metrics to their respective lists\n",
    "    y_hat_train = linreg.predict(X_train)\n",
    "    y_hat_test = linreg.predict(X_test)\n",
    "    train_mses.append(mean_squared_error(y_train, y_hat_train))\n",
    "    test_mses.append(mean_squared_error(y_test, y_hat_test))\n",
    "\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(t_sizes, train_avg, label='Training Error')\n",
    "ax.scatter(t_sizes, test_avg, label='Testing Error')\n",
    "ax.legend();\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension\n",
    "\n",
    "Repeat the previous example, but for each train-test split size, generate 10 iterations of models/errors and save the average train/test error. This will help account for any particularly good/bad models that might have resulted from poor/good splits in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEDCAYAAAAlRP8qAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAdCUlEQVR4nO3de3RV5bnv8e9jiBAFCZUoSJSLtYBiBE1RwUuQ7dB6pW61Urxg9ziIuouiYosdpWrHHuXIGXt7wGIGPV6ro5UjbrzhdheUglZLg9wFrNXsTcDWmI4EOaCG+Jw/1kpIQlayVphZc66Z32eMNTIv75zzyZvkyTvf9a53mrsjIiK577CwAxARkWAooYuIxIQSuohITCihi4jEhBK6iEhMKKGLiMREqAndzB43s0/NbHMaZQeb2Qoz22hmK82sOBsxiojkirBb6E8CF6dZ9n8BT7t7CfAg8IuuCkpEJBeFmtDdfRXw9+bbzOxEM/sPM1trZqvNbERy18nAiuTym8CVWQxVRCTywm6ht2UR8EN3PwO4B1iY3L4B+Mfk8neBPmZ2dAjxiYhEUo+wA2jOzHoD44D/a2aNm3smv94DPGJmU4FVwE5gf7ZjFBGJqkgldBJ3DLXuPrr1DnffBVwFTYn/H929LrvhiYhEV6S6XNx9N/CxmV0DYAmnJZf7m1ljvLOBx0MKU0QkksIetvgb4B1guJlVmdk/AVOAfzKzDcAWDrz5WQZsN7MPgGOBfwkhZBGRyDJNnysiEg+R6nIREZHOC+1N0f79+/uQIUPCuryISE5au3btZ+5e1Na+0BL6kCFDqKioCOvyIiI5ycz+K9U+dbmIiMSEErqISEwooYuIxESkPilaX19PVVUVX3zxRdihSDO9evWiuLiY/Pz8sEMRkXZEKqFXVVXRp08fhgwZQrO5XCRE7k5NTQ1VVVUMHTo07HBEpB2R6nL54osvOProo5XMI8TMOProo3XXJBKEjYvh30bB/YWJrxsXB3r6SLXQASXzCNLPRCQAGxfDyzOgfl9ivW5HYh2g5NpALhGpFrqISGytePBAMm9Uvy+xPSBK6M3U1NQwevRoRo8ezYABAxg0aFDT+ldffdXusRUVFcyYMaPDa4wbNy6QWFeuXEnfvn2b4hs9ejTLly8P5Nwi0gXqqjLb3gmR63IJ09FHH8369esBuP/+++nduzf33HNP0/79+/fTo0fbVVZaWkppaWmH1/jDH/4QSKwA5557Lq+88krK/e6Ou3PYYYe1uZ5KQ0MDeXl5gcUpIkDf4kQ3S1vbA5LTLfSl63Yyfu4bDP3xq4yf+wZL1+0M/BpTp07lrrvuYsKECfzoRz9izZo1jBs3jjFjxjBu3Di2b98OJFrMl112GZD4Z/CDH/yAsrIyhg0bxvz585vO17t376byZWVlXH311YwYMYIpU6bQOPPlsmXLGDFiBOeccw4zZsxoOm86KisrGTlyJLfddhunn346q1evbrG+Y8cOZs2axahRozj11FN57rnnmuKZMGEC3//+9zn11FMDqTsRaWbiHMgvaLktvyCxPSA520Jfum4ns1/YxL76BgB21u5j9gubAJg0ZlCg1/rggw9Yvnw5eXl57N69m1WrVtGjRw+WL1/Offfdx5IlSw46Ztu2bbz55pt8/vnnDB8+nFtvvfWgcdzr1q1jy5YtHHfccYwfP563336b0tJSbrnlFlatWsXQoUOZPHlyyrhWr17N6NGjm9aXLFlCXl4e27dv54knnmDhwoVUVla2WF+yZAnr169nw4YNfPbZZ3z729/mvPPOA2DNmjVs3rxZwxNFukLjG58rHkx0s/QtTiTzgN4QhRxO6PNe396UzBvtq29g3uvbA0/o11xzTVMXRF1dHTfddBN//vOfMTPq6+vbPObSSy+lZ8+e9OzZk2OOOYa//e1vFBe3vLUaO3Zs07bRo0dTWVlJ7969GTZsWFNSnTx5MosWLWrzGm11uVRWVjJ48GDOOuuspm3N19966y0mT55MXl4exx57LOeffz5/+tOfOOqooxg7dqySuUhXKrk20ATeWs52ueyq3ZfR9kNx5JFHNi3/9Kc/ZcKECWzevJmXX3455fjsnj17Ni3n5eWxf//Bz7Nuq0wQDxxpHm/r9fbO3/o4EcktOZvQjyssyGh7UOrq6hg0KHEH8OSTTwZ+/hEjRvDRRx9RWVkJ0NTHHZTzzjuP5557joaGBqqrq1m1ahVjx44N9BoiEo6cTeizLhpOQX7LkRgF+XnMumh4l1733nvvZfbs2YwfP56GhoaOD8hQQUEBCxcu5OKLL+acc87h2GOPpW/fvm2WbexDb3w9//zzHZ7/u9/9LiUlJZx22mlccMEFPPTQQwwYMCDob0NEQhDaM0VLS0u99QMutm7dysiRI9M+x9J1O5n3+nZ21e7juMICZl00PPD+8zDs2bOH3r174+7cfvvtnHTSScycOTPUmDL92YhI1zCzte7e5hjpnH1TFBKjWeKQwFv71a9+xVNPPcVXX33FmDFjuOWWW8IOSURyQE4n9LiaOXNm6C1yEck9OduHLiIiLSmhi4jERNoJ3czyzGydmR00eYiZlZlZnZmtT76C+yyriIikJZM+9DuArcBRKfavdvf0Jx0REZFApZXQzawYuBT4F+CuLo0oRDU1NUycOBGAv/71r+Tl5VFUVAQk5jk5/PDD2z1+5cqVHH744U1T5JaXl3PEEUdw4403HnJsZWVlfPLJJxQUJD449c1vfjOtceci0n2k20J/GLgX6NNOmbPNbAOwC7jH3bccYmxZ19H0uR1ZuXIlvXv3bkro06dPDzS+Z599tt0peltP79vedL/tHSciuanDv2Izuwz41N3XmllZimLvAYPdfY+ZXQIsBU5q41zTgGkAJ5xwQidDbmbj4i6duQxg7dq13HXXXezZs4f+/fvz5JNPMnDgQObPn095eTk9evTg5JNPZu7cuZSXl5OXl8czzzzDggULWLFiRdM/hbKyMs4880zefPNNamtreeyxxzj33HPZu3cvU6dOZdu2bYwcOZLKykp++ctfpjW3OiSm9/3GN77BunXrOP3006mpqWmxfsMNNzB9+nT27t3LiSeeyOOPP06/fv0oKytj3LhxvP3221xxxRXcfffdgdabiGRfOs2y8cAVyUTdCzjKzJ5x9+sbC7j77mbLy8xsoZn1d/fPmp/I3RcBiyDxSdFDijwLz+dzd374wx/y4osvUlRUxHPPPcdPfvITHn/8cebOncvHH39Mz549qa2tpbCwkOnTp7do1a9YsaLF+fbv38+aNWtYtmwZDzzwAMuXL2fhwoX069ePjRs3snnz5hbT4bY2ZcqUpi6XCy+8kHnz5gEtp/edOnVqi/WSkhIWLFjA+eefz5w5c3jggQd4+OGHAaitreX3v/99IHUlIuHrMKG7+2xgNiRGs5DoTrm+eRkzGwD8zd3dzMaSGD1TE3i0zbX3fL6AEvqXX37J5s2bufDCC4HEk3wGDhwIQElJCVOmTGHSpElMmjQprfNdddVVAJxxxhlNk2+99dZb3HHHHQCMGjWKkpKSlMen6nJpPr1v8/W6ujpqa2s5//zzAbjpppu45pprmsp973vfSytuEckNne44NbPpAO5eDlwN3Gpm+4F9wHXe1ZPEZOH5fO7OKaecwjvvvHPQvldffZVVq1bx0ksv8fOf/5wtWzp+y6Bxutzm0+l29XS5mRwnIrktow8WufvKxqGJ7l6eTOa4+yPufoq7n+buZ7l7cA/OTCXVc/gCfD5fz549qa6ubkro9fX1bNmyha+//podO3YwYcIEHnroIWpra9mzZw99+vTh888/z+ga55xzDosXLwbg/fffZ9OmTYHF37dvX/r168fq1asB+PWvf93UWheR+MndoQ0T57TsQ4fAn8932GGH8fzzzzNjxgzq6urYv38/d955J9/61re4/vrrqaurw92ZOXMmhYWFXH755Vx99dW8+OKLLFiwIK1r3Hbbbdx0002UlJQwZswYSkpKUk6X27wPvX///ixfvrzD8z/11FNNb4oOGzaMJ554Iv0KEJGcktPT52ZjlEtXa2hooL6+nl69evGXv/yFiRMn8sEHH3Q45j3bNH2uSDTEdvrcrn4+Xzbs3buXCRMmUF9fj7vz6KOPRi6Zi0huyO2EHgN9+vSh9Z2KiEhnRG62xbC6gCQ1/UxEckOkEnqvXr2oqalRAokQd6empoZevXqFHYqIdCBSXS7FxcVUVVVRXV0ddijSTK9evSguDm44qIh0jUgl9Pz8fIYOHRp2GCIiOSlSXS4iItJ5SugiIjGhhC4iEhNK6CIiMaGELiISE0roIiIxoYQuIhITSugiIjGhhC4iEhNK6CIiMaGELiISE2kndDPLM7N1ZvZKG/vMzOab2YdmttHMTg82TBER6UgmLfQ7gK0p9n0HOCn5mgY8eohxiYhIhtJK6GZWDFwK/J8URa4EnvaEd4FCMxsYUIwiIpKGdFvoDwP3Al+n2D8I2NFsvSq5rQUzm2ZmFWZWoTnPRUSC1WFCN7PLgE/dfW17xdrYdtBjh9x9kbuXuntpUVFRBmGKiEhH0mmhjweuMLNK4LfABWb2TKsyVcDxzdaLgV2BRCgiImnpMKG7+2x3L3b3IcB1wBvufn2rYi8BNyZHu5wF1Ln7J8GHKyIiqXT6EXRmNh3A3cuBZcAlwIfAXuDmQKITEZG0ZZTQ3X0lsDK5XN5suwO3BxmYiIhkRp8UFRGJCSV0EZGYUEIXEYkJJXQRkZhQQhcRiQkldBGRmFBCFxGJCSV0EZGYUEIXEYkJJXQRkZhQQhcRiQkldBGRmFBCFxGJCSV0EZGYUEIXEYkJJXQRkZhQQhcRiQkldBGRmOgwoZtZLzNbY2YbzGyLmT3QRpkyM6szs/XJ15yuCVdERFJJ55miXwIXuPseM8sH3jKz19z93VblVrv7ZcGHKCIi6egwoScfAL0nuZqffHlXBiUiIplLqw/dzPLMbD3wKfA7d/9jG8XOTnbLvGZmp6Q4zzQzqzCziurq6s5HLSIiB0krobt7g7uPBoqBsWY2qlWR94DB7n4asABYmuI8i9y91N1Li4qKOh+1iIgcJKNRLu5eC6wELm61fbe770kuLwPyzax/QDGKiEga0hnlUmRmhcnlAuAfgG2tygwwM0suj02etybwaEVEJKV0RrkMBJ4yszwSiXqxu79iZtMB3L0cuBq41cz2A/uA65JvpoqISJakM8plIzCmje3lzZYfAR4JNjQREcmEPikqIhITSugiIjGhhC4iEhNK6CIiMaGELiISE0roIiIxoYQuIhITSugiIjGhhC4iEhNK6CIiMaGELiISE0roIiIxoYQuIhITSugiIjGhhC4iEhNK6CIiMaGELiISE0roIiIxkc5DonuZ2Roz22BmW8zsgTbKmJnNN7MPzWyjmZ3eNeGKiEgq6Twk+kvgAnffY2b5wFtm9pq7v9uszHeAk5KvM4FHk19FRCRLOmyhe8Ke5Gp+8uWtil0JPJ0s+y5QaGYDgw1VRETak1Yfupnlmdl64FPgd+7+x1ZFBgE7mq1XJbe1Ps80M6sws4rq6upOhiwiIm1JK6G7e4O7jwaKgbFmNqpVEWvrsDbOs8jdS929tKioKONgRUQktYxGubh7LbASuLjVrirg+GbrxcCuQwlMREQyk84olyIzK0wuFwD/AGxrVewl4MbkaJezgDp3/yToYEVEJLV0RrkMBJ4yszwS/wAWu/srZjYdwN3LgWXAJcCHwF7g5i6KV0REUugwobv7RmBMG9vLmy07cHuwoYmISCb0SVERkZhQQhcRiQkldBGRmFBCFxGJCSV0EZGYUEIXEYkJJXQRkZhQQhcRiQkldBGRmFBCFxGJCSV0EZGYUEIXEYkJJXQRkZhQQhcRiQkldBGRmFBCFxGJCSV0EZGYUEIXEYmJdB4SfbyZvWlmW81si5nd0UaZMjOrM7P1ydecrglXRERSSech0fuBu939PTPrA6w1s9+5+/utyq1298uCD1FE5BBtXAwrHoS6KuhbDBPnQMm1YUcVuHQeEv0J8Ely+XMz2woMAlondBGR6Nm4GF6eAfX7Eut1OxLrELuknlEfupkNAcYAf2xj99lmtsHMXjOzU1IcP83MKsysorq6OvNoRUQyteLBA8m8Uf2+xPaYSTuhm1lvYAlwp7vvbrX7PWCwu58GLACWtnUOd1/k7qXuXlpUVNTJkEVEMlBXldn2HJZWQjezfBLJ/Fl3f6H1fnff7e57ksvLgHwz6x9opCIindG3OLPtOSydUS4GPAZsdfd/TVFmQLIcZjY2ed6aIAMVEemUiXMgv6DltvyCxPaYSWeUy3jgBmCTma1PbrsPOAHA3cuBq4FbzWw/sA+4zt09+HBFJKdEYXRJ4/XCjiMLLKy8W1pa6hUVFaFcW0SyoPXoEki0jC+fH8tkmi1mttbdS9vap0+KikjX6EajS6JCCV1EukY3Gl0SFUroItI1utHokqhQQheRrtGNRpdEhRK6iHSNkmsTb4D2PR6wxFe9Idql0hm2KCLSOSXXKoFnkVroIiIxoYQuIhITSugiIjGhhC4iEhNK6CIiMaGELiISE0roIiIxoYQuEkcbF8O/jYL7CxNfNy4OOyLJAn2wqDOiMMezSCrd6KHI0pJa6Jlq/GOp2wH4gT8WtYAkKjRtbbelhJ6pKP2xROW2WnFEi6at7bbU5ZKpqPyxROW2WnFET9/i5B1kG9sl1tJ5SPTxZvammW01sy1mdkcbZczM5pvZh2a20cxO75Joo9ACi8ocz1G5U1Ac0aNpa7utdLpc9gN3u/tI4CzgdjM7uVWZ7wAnJV/TgEcDjRKi03cdlT+WqNwpKI7o0bS13VaHXS7u/gnwSXL5czPbCgwC3m9W7ErgaU88cfpdMys0s4HJY4PRXgssm7+oUXmCeFRuqxXHwaIwCkrT1nZLGb0pamZDgDHAH1vtGgQ0/2uqSm5rffw0M6sws4rq6urMIo1SC6zkWpi5Ge6vTXwN4w8nKncKiqOlqNxJSreUdkI3s97AEuBOd9/dencbh/hBG9wXuXupu5cWFRVlFmlU+q6jIiq31YqjJfXlS4jSGuViZvkkkvmz7v5CG0WqgOObrRcDuw49vGYmzmk5igH0Rk9UbqsVxwFRupOUbiedUS4GPAZsdfd/TVHsJeDG5GiXs4C6QPvPITotMJH26E5SQpROC308cAOwyczWJ7fdB5wA4O7lwDLgEuBDYC9wc+CRQjRaYCLt0Z2khCidUS5v0XYfefMyDtweVFAiOSsqo6CkW9InRUUCtrRhPPO+nM+uL/ZxXK8CZjUMZ1LYQUm3oIQuEqCl63Yy+4VN7KtvAGBn7T5mv7AJgEljDhrJKxIoTc4lEqB5r29vSuaN9tU3MO/17SFFJN2JWugiAdpVuy+j7XG3dN1O5r2+nV21+ziusIBZFw3XnUoXUgtdJEDHFRZktD3OGrufdtbuwznQ/bR03c6wQ4stJXSJjaXrdjJ+7hsM/fGrjJ/7RiiJY9ZFwynIz2uxrSA/j1kXDc9qHFGoC3U/ZV9Odbno9k1SicqbkY3XCvP3NCp1oe6n7MuZhB6VX1I5WBT+0bbXGsx2LJPGDAr1dzIqdXFcYQE720je3bH7KVtypstFt2/RFJV+UrUGD4hKXUSl+6k7yZmEHpVf0ihRP+kBejPygKjUxaQxg/jFVacyqLAAAwYVFvCLq07VHXUXypkulyjdvkWhiyEqXVBR+Uc766LhLeoDum9rMEp1EXb3U3eTMy30qNy+RaWLQS3jltQaPEB10X3lTAs9CqMHGq8fhTec1DI+mFqDB6guuqecSegQjV/SqCTSqHRBReUfrYjkWEKPgqgkUrWMRaS1nOlDj4qo9OWrn1REWlMLPUNR6mJQy1gkPVEYmZYNSuidoEQqkjuiMsQ3G9J5SPTjZvapmW1Osb/MzOrMbH3ypYcnikhkRGWIbzak00J/EngEeLqdMqvd/bJAIhIRCVBURqZlQ4ctdHdfBfw9C7GIiAQuKh9+y4agRrmcbWYbzOw1MzslVSEzm2ZmFWZWUV1dHdClRURSi8rItGwIIqG/Bwx299OABcDSVAXdfZG7l7p7aVFRUQCXFhFpX3ca4nvIo1zcfXez5WVmttDM+rv7Z4d6bhGRIHSXkWmH3EI3swFmZsnlsclz1hzqeUVEJDMdttDN7DdAGdDfzKqAnwH5AO5eDlwN3Gpm+4F9wHXu7l0WsYiItKnDhO7ukzvY/wiJYY0iIhIizeUiIhITSugiIjGhhC4iEhNK6CIiMaGELiISE0roIiIxoYQuIhITSugiIjGhhC4iEhNK6CIiMaFnioqIZElXP6xaCV1EJAuy8bBqdbmIiGRBNh5WrYQuIpIF2XhYtRK6iEgWZONh1UroIiJZkI2HVetNURGRLGh841OjXEREYqCrH1bdYZeLmT1uZp+a2eYU+83M5pvZh2a20cxODz5MERHpSDp96E8CF7ez/zvAScnXNODRQw9LREQy1WFCd/dVwN/bKXIl8LQnvAsUmtnAoAIUEZH0BDHKZRCwo9l6VXLbQcxsmplVmFlFdXV1AJcWEZFGQSR0a2Obt1XQ3Re5e6m7lxYVFQVwaRERaRTEKJcq4Phm68XAro4OWrt27Wdm9l+dvGZ/4LNOHtuVohoXRDc2xZUZxZWZOMY1ONWOIBL6S8A/m9lvgTOBOnf/pKOD3L3TTXQzq3D30s4e31WiGhdENzbFlRnFlZnuFleHCd3MfgOUAf3NrAr4GZAP4O7lwDLgEuBDYC9wc9BBiohIxzpM6O4+uYP9DtweWEQiItIpuTqXy6KwA0ghqnFBdGNTXJlRXJnpVnFZooEtIiK5Lldb6CIi0ooSuohITEQuoZvZxWa2PTnZ14/b2F9mZnVmtj75mpPusSHGVWlmm5LbK7IZV7PY1pvZFjP7fSbHhhRXaPVlZrOa/Qw3m1mDmX0j3e8ppLjCrK++ZvaymW1I/hxvTvfYEOMKs776mdm/W2IiwzVmNirdY9Pi7pF5AXnAX4BhwOHABuDkVmXKgFc6c2wYcSX3VQL9Q6qvQuB94ITk+jERqa824wq7vlqVvxx4Iwr1lSqusOsLuA/4n8nlIhLzPh0edn2liisC9TUP+FlyeQSwIsjfr6i10McCH7r7R+7+FfBbEpN/dfWxYZ77UKQT1/eBF9z9vwHc/dMMjg0jrq6U6fc8GfhNJ4/NVlxdKZ24HOhjZgb0JpE496d5bBhxdaV04joZWAHg7tuAIWZ2bJrHdihqCT3dib7OTt5KvWZmp2R4bLbjgsQv13+a2VozmxZQTOnG9S2gn5mtTF7/xgyODSMuCLe+ADCzI0hMG70k02OzHBeEW1+PACNJTPexCbjD3b9O89gw4oJw62sDcBWAmY0l8TH+4jSP7VDUnliUzkRf7wGD3X2PmV0CLCUxF3vak4RlOS6A8e6+y8yOAX5nZts8MS1xNuLqAZwBTAQKgHfM7N00j816XO7+AeHWV6PLgbfdvXHq6LDrq1HruCDc+roIWA9cAJyYvP7qNI/Nelzuvptw62su8L/NbD2JfzTrSNw5BFJfUWuhdzjRl7vvdvc9yeVlQL6Z9U/n2JDiwt13Jb9+Cvw7idurrMSVLPMf7v7/3P0zYBVwWprHhhFX2PXV6DpadmuEXV+p4gq7vm4m0XXm7v4h8DGJvuGw6ytVXKHWVzJP3Ozuo4EbSfTvf5zm99SxoN8YOJQXiVbbR8BQDrwxcEqrMgM48IGoscB/k/jv1uGxIcV1JNAnuf1I4A/AxVmMaySJPrsewBHAZmBUBOorVVyh1leyXF8Sfa5HZnpsCHGF/fv1KHB/cvlYYCeJmQTD/v1KFVfY9VXIgTdn/weJhwMF9vt1yN9E0C8SE319QOId358kt00HpieX/xnYkvyG3wXGtXds2HGReNd6Q/K1JdtxJddnkRhRshm4Mwr1lSquiNTXVOC36Rwbdlxh1xdwHPCfJLoPNgPXR6G+UsUVgfo6G/gzsA14AegXZH3po/8iIjERtT50ERHpJCV0EZGYUEIXEYkJJXQRkZhQQhcRiQkldBGRmFBCFxGJif8PkwgfxsnaEjgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_sizes = np.linspace(0.5, 0.9, 10)\n",
    "train_avg_1 = []\n",
    "test_avg_1 = []\n",
    "for num in t_sizes:\n",
    "    train_avg = []\n",
    "    test_avg = []\n",
    "    for i in range(10):\n",
    "\n",
    "        #split into train and test\n",
    "        train, test = train_test_split(ames, test_size = num, random_state=5)\n",
    "\n",
    "        X_train = train.drop(['SalePrice'], axis=1)\n",
    "        y_train = train['SalePrice']\n",
    "\n",
    "        X_test = test.drop(['SalePrice'], axis=1)\n",
    "        y_test = test['SalePrice']\n",
    "\n",
    "        #transform data\n",
    "        continuous = ['LotArea', '1stFlrSF', 'GrLivArea']\n",
    "        categoricals = ['BldgType', 'KitchenQual', 'Street']\n",
    "\n",
    "        # Instantiate transformers\n",
    "        log_transformer = FunctionTransformer(np.log, validate=True)\n",
    "        ohe = OneHotEncoder(drop='first', sparse=False)\n",
    "\n",
    "        # Fit transformers\n",
    "        log_transformer.fit(X_train[continuous])\n",
    "        ohe.fit(X_train[categoricals])\n",
    "\n",
    "        # Transform training data\n",
    "        X_train = pd.concat([\n",
    "        pd.DataFrame(log_transformer.transform(X_train[continuous]), index=X_train.index),\n",
    "        pd.DataFrame(ohe.transform(X_train[categoricals]), index=X_train.index)\n",
    "        ], axis=1)\n",
    "\n",
    "        # Transform test data\n",
    "        X_test = pd.concat([\n",
    "        pd.DataFrame(log_transformer.transform(X_test[continuous]), index=X_test.index),\n",
    "        pd.DataFrame(ohe.transform(X_test[categoricals]), index=X_test.index)\n",
    "        ], axis=1)\n",
    "\n",
    "        #Build Model\n",
    "        linreg = LinearRegression()\n",
    "        linreg.fit(X_train, y_train)\n",
    "\n",
    "        y_hat_train = linreg.predict(X_train)\n",
    "        y_hat_test = linreg.predict(X_test)\n",
    "\n",
    "        train_mse = mean_squared_error(y_train, y_hat_train)\n",
    "        test_mse = mean_squared_error(y_test, y_hat_test)\n",
    "        \n",
    "        train_avg.append(train_mse)\n",
    "        test_avg.append(test_mse)\n",
    "        \n",
    "    train_avg_1.append(np.mean(train_avg))\n",
    "    test_avg_1.append(np.mean(test_avg))\n",
    "\n",
    "    \n",
    "print(len(train_avg_1), len(test_avg_1))\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(t_sizes, train_avg_1, label='Training Error')\n",
    "ax.scatter(t_sizes, test_avg_1, label='Testing Error')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening here? Evaluate your result!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now practiced your knowledge of MSE and used your train-test split skills to validate your model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
